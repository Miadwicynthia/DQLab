{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37928660",
   "metadata": {},
   "source": [
    "# Pengenalan Project\n",
    "\n",
    "membuat recommender system yang menggunakan Content/feature dari film/entitas tersebut, kemudian melakukan perhitungan terhadap kesamaannya satu dan yang lain sehingga ketika kita menunjuk ke satu film, kita akan mendapat beberapa film lain yang memiliki kesamaan dengan film tersebut. Hal ini biasa kita sebut sebagai Content Based Recommender System.\n",
    "\n",
    "Dengan membandingkan kesamaan plot yang ada dan genre yang ada, ketika audience lebih menyukai film Narnia, maka content based recommender system ini akan juga merekomendasikan film seperti Harry Potter atau The Lords of The Rings yang memiliki genre yang mirip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae43b4a7",
   "metadata": {},
   "source": [
    "# Import Basics Library and File Unloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "662f264d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library yang dibutuhkan\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "#lakukan pembacaan dataset\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv') #untuk menyimpan movie_rating_df.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0caf11",
   "metadata": {},
   "source": [
    "# Menampilkan 5 data teratas dan info data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5306fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst titleType            primaryTitle           originalTitle  \\\n",
      "0  tt0000001     short              Carmencita              Carmencita   \n",
      "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
      "2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
      "3  tt0000004     short             Un bon bock             Un bon bock   \n",
      "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
      "\n",
      "   isAdult  startYear  endYear  runtimeMinutes                    genres  \\\n",
      "0        0     1894.0      NaN             1.0         Documentary,Short   \n",
      "1        0     1892.0      NaN             5.0           Animation,Short   \n",
      "2        0     1892.0      NaN             4.0  Animation,Comedy,Romance   \n",
      "3        0     1892.0      NaN            12.0           Animation,Short   \n",
      "4        0     1893.0      NaN             1.0              Comedy,Short   \n",
      "\n",
      "   averageRating  numVotes  \n",
      "0            5.6      1608  \n",
      "1            6.0       197  \n",
      "2            6.5      1285  \n",
      "3            6.1       121  \n",
      "4            6.1      2050  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 751614 entries, 0 to 751613\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   tconst          751614 non-null  object \n",
      " 1   titleType       751614 non-null  object \n",
      " 2   primaryTitle    751614 non-null  object \n",
      " 3   originalTitle   751614 non-null  object \n",
      " 4   isAdult         751614 non-null  int64  \n",
      " 5   startYear       751614 non-null  float64\n",
      " 6   endYear         16072 non-null   float64\n",
      " 7   runtimeMinutes  751614 non-null  float64\n",
      " 8   genres          486766 non-null  object \n",
      " 9   averageRating   751614 non-null  float64\n",
      " 10  numVotes        751614 non-null  int64  \n",
      "dtypes: float64(4), int64(2), object(5)\n",
      "memory usage: 63.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "#tampilkan 5 baris teratas dari movive_rating_df\n",
    "print(movie_rating_df.head())\n",
    "\n",
    "#tampilkan info mengenai tipe data dari tiap kolom\n",
    "print(movie_rating_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb36ed38",
   "metadata": {},
   "source": [
    "# Add Actors Dataframe\n",
    "\n",
    "menambahkan metadata lain seperti aktor/aktris yang bermain di film tersebut, kita akan menggunakan dataframe lain kemudian akan melakukan join dengan dataframe movie_rating_df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22692c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       nconst          primaryName birthYear deathYear  \\\n",
      "0   nm1774132    Nathan McLaughlin      1973        \\N   \n",
      "1  nm10683464        Bridge Andrew        \\N        \\N   \n",
      "2   nm1021485    Brandon Fransvaag        \\N        \\N   \n",
      "3   nm6940929   Erwin van der Lely        \\N        \\N   \n",
      "4   nm5764974  Svetlana Shypitsyna        \\N        \\N   \n",
      "\n",
      "                    primaryProfession                           knownForTitles  \n",
      "0  special_effects,make_up_department  tt0417686,tt1713976,tt1891860,tt0454839  \n",
      "1                               actor                                tt7718088  \n",
      "2                       miscellaneous                                tt0168790  \n",
      "3                       miscellaneous                                tt4232168  \n",
      "4                             actress                                tt3014168  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   nconst             1000 non-null   object\n",
      " 1   primaryName        1000 non-null   object\n",
      " 2   birthYear          1000 non-null   object\n",
      " 3   deathYear          1000 non-null   object\n",
      " 4   primaryProfession  891 non-null    object\n",
      " 5   knownForTitles     1000 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 47.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "#Simpan actor_name.csv pada variable name_df \n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "\n",
    "#Tampilkan 5 baris teratas dari name_df\n",
    "print(name_df.head())\n",
    "\n",
    "#Tampilkan informasi mengenai tipe data dari tiap kolom pada name_df\n",
    "print(name_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bd81dd",
   "metadata": {},
   "source": [
    "# Add Directors and Writers Dataframe\n",
    "\n",
    "Dataframe yang akan ditambahkan selanjutnya adalah dataframe yang berisi directors dan writers dari film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4871e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst                   director_name  \\\n",
      "0  tt0011414                  David Kirkland   \n",
      "1  tt0011890               Roy William Neill   \n",
      "2  tt0014341  Buster Keaton,John G. Blystone   \n",
      "3  tt0018054                Cecil B. DeMille   \n",
      "4  tt0024151                     James Cruze   \n",
      "\n",
      "                                       writer_name  \n",
      "0                          John Emerson,Anita Loos  \n",
      "1     Arthur F. Goodrich,Burns Mantle,Mary Murillo  \n",
      "2  Jean C. Havez,Clyde Bruckman,Joseph A. Mitchell  \n",
      "3                                Jeanie Macpherson  \n",
      "4                 Max Miller,Wells Root,Jack Jevne  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 986 entries, 0 to 985\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   tconst         986 non-null    object\n",
      " 1   director_name  986 non-null    object\n",
      " 2   writer_name    986 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 23.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "#Menyimpan dataset pada variabel director_writers\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "\n",
    "#Manampilkan 5 baris teratas\n",
    "print(director_writers.head())\n",
    "\n",
    "#Menampilkan informasi tipe data\n",
    "print(director_writers.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad942511",
   "metadata": {},
   "source": [
    "# Convert into List\n",
    "\n",
    "mengubah director_name dan writer_name dari string menjadi list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba538aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tconst                      director_name  \\\n",
      "0  tt0011414                   [David Kirkland]   \n",
      "1  tt0011890                [Roy William Neill]   \n",
      "2  tt0014341  [Buster Keaton, John G. Blystone]   \n",
      "3  tt0018054                 [Cecil B. DeMille]   \n",
      "4  tt0024151                      [James Cruze]   \n",
      "\n",
      "                                         writer_name  \n",
      "0                         [John Emerson, Anita Loos]  \n",
      "1   [Arthur F. Goodrich, Burns Mantle, Mary Murillo]  \n",
      "2  [Jean C. Havez, Clyde Bruckman, Joseph A. Mitc...  \n",
      "3                                [Jeanie Macpherson]  \n",
      "4               [Max Miller, Wells Root, Jack Jevne]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "\n",
    "#Mengubah director_name menjadi list\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "#Tampilkan 5 data teratas\n",
    "print(director_writers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61d57d",
   "metadata": {},
   "source": [
    "# Update name_df\n",
    "\n",
    "membutuhkan kolom nconst, primaryName, dan knownForTitles pada name_df untuk mencocokkan aktor/aktris ini dengan film yang ada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b6660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "#Kita hanya akan membutuhkan kolom nconst, primaryName, dan knownForTitles\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "\n",
    "#Tampilkan 5 baris teratas dari name_df\n",
    "print(name_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6189b",
   "metadata": {},
   "source": [
    "# Movies per Actor\n",
    "\n",
    "variasi dari jumlah film yang dapat dibintangi oleh seorang aktor.\n",
    "1. Melakukan pengecekan variasi jumlah film yang dibintangi oleh aktor.\n",
    "2. Mengubah kolom 'knownForTitles' menjadi list of list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4da57078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 2 3]\n",
      "       nconst          primaryName  \\\n",
      "0   nm1774132    Nathan McLaughlin   \n",
      "1  nm10683464        Bridge Andrew   \n",
      "2   nm1021485    Brandon Fransvaag   \n",
      "3   nm6940929   Erwin van der Lely   \n",
      "4   nm5764974  Svetlana Shypitsyna   \n",
      "\n",
      "                                 knownForTitles  \n",
      "0  [tt0417686, tt1713976, tt1891860, tt0454839]  \n",
      "1                                   [tt7718088]  \n",
      "2                                   [tt0168790]  \n",
      "3                                   [tt4232168]  \n",
      "4                                   [tt3014168]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "\n",
    "#Melakukan pengecekan variasi\n",
    "print(name_df['knownForTitles'].apply(lambda x: len(x.split(','))).unique())\n",
    "\n",
    "#Mengubah knownForTitles menjadi list of list\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "#Mencetak 5 baris teratas\n",
    "print(name_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4369f8",
   "metadata": {},
   "source": [
    "# Korespondensi 1 - 1\n",
    "\n",
    "seorang aktor dapat membintangi 1 sampai 4 film, diperlukan untuk membuat table yang mempunyai relasi 1-1 dari aktor ke masing-masing title movie tersebut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d75bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "#menyiapkan bucket untuk dataframe\n",
    "df_uni = []\n",
    "\n",
    "for x in ['knownForTitles']:\n",
    "\t#mengulang index dari tiap baris sampai tiap elemen dari knownForTitles\n",
    "\tidx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "\n",
    "\t#memecah values dari list di setiap baris dan menggabungkan nya dengan rows lain menjadi dataframe\n",
    "\tdf1 = pd.DataFrame({\n",
    "\t\tx: np.concatenate(name_df[x].values)\n",
    "\t})\n",
    "\n",
    "\t#mengganti index dataframe tersebut dengan idx yang sudah kita define di awal\n",
    "\tdf1.index = idx\n",
    "\n",
    "\t#untuk setiap dataframe yang terbentuk, kita menambahkan ke dataframe bucket\n",
    "\tdf_uni.append(df1)\n",
    "\n",
    "#menggabungkan semua dataframe menjadi satu\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "\n",
    "#join dengan value dari dataframe yang awal\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "\n",
    "#select kolom sesuai dengan dataframe awal\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "print(unnested_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a04a9b9",
   "metadata": {},
   "source": [
    "# Mengelompokkan primaryName menjadi list group by knownForTitles\n",
    "\n",
    "melakukan grouping kembali pada kolom player karena yang kita inginkan adalah level movie untuk melakukan movie recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "\n",
    "#menyiapkan bucket untuk dataframe\n",
    "df_uni = []\n",
    "\n",
    "for col in ['primaryName']:\n",
    "    #agregasi kolom PrimaryName sesuai group_col yang sudah di define di atas\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    #Lakukan append\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "print(df_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b5adec",
   "metadata": {},
   "source": [
    "# Join table\n",
    "1. join antara movie table dan cast table  ( field knownForTitles dan tconst)\n",
    "2. join antara base_df dengan director_writer table (field tconst dan tconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9d180d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  knownForTitles           cast_name     tconst titleType  \\\n",
      "0      tt0011414  [Natalie Talmadge]  tt0011414     movie   \n",
      "1      tt0011890  [Natalie Talmadge]  tt0011890     movie   \n",
      "2      tt0014341  [Natalie Talmadge]  tt0014341     movie   \n",
      "3      tt0018054     [Reeka Roberts]  tt0018054     movie   \n",
      "4      tt0024151     [James Hackett]  tt0024151     movie   \n",
      "\n",
      "             primaryTitle           originalTitle  isAdult  startYear  \\\n",
      "0         The Love Expert         The Love Expert        0     1920.0   \n",
      "1               Yes or No               Yes or No        0     1920.0   \n",
      "2         Our Hospitality         Our Hospitality        0     1923.0   \n",
      "3       The King of Kings       The King of Kings        0     1927.0   \n",
      "4  I Cover the Waterfront  I Cover the Waterfront        0     1933.0   \n",
      "\n",
      "   endYear  runtimeMinutes                   genres  averageRating  numVotes  \\\n",
      "0      NaN            60.0           Comedy,Romance            4.9       136   \n",
      "1      NaN            72.0                      NaN            6.3         7   \n",
      "2      NaN            65.0  Comedy,Romance,Thriller            7.8      9621   \n",
      "3      NaN           155.0  Biography,Drama,History            7.3      1826   \n",
      "4      NaN            80.0            Drama,Romance            6.3       455   \n",
      "\n",
      "                       director_name  \\\n",
      "0                   [David Kirkland]   \n",
      "1                [Roy William Neill]   \n",
      "2  [Buster Keaton, John G. Blystone]   \n",
      "3                 [Cecil B. DeMille]   \n",
      "4                      [James Cruze]   \n",
      "\n",
      "                                         writer_name  \n",
      "0                         [John Emerson, Anita Loos]  \n",
      "1   [Arthur F. Goodrich, Burns Mantle, Mary Murillo]  \n",
      "2  [Jean C. Havez, Clyde Bruckman, Joseph A. Mitc...  \n",
      "3                                [Jeanie Macpherson]  \n",
      "4               [Max Miller, Wells Root, Jack Jevne]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "#join antara movie table dan cast table \n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "\n",
    "#join antara base_df dengan director_writer table\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "print(base_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a836181",
   "metadata": {},
   "source": [
    "# Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072e3c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "#Melakukan drop terhadap kolom knownForTitles\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "print(base_drop.info())\n",
    "\n",
    "#Mengganti nilai NULL pada kolom genres dengan 'Unknown'\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "\n",
    "#Melakukan perhitungan jumlah nilai NULL pada tiap kolom\n",
    "print(base_drop.isnull().sum())\n",
    "\n",
    "#Mengganti nilai NULL pada kolom dorector_name dan writer_name dengan 'Unknown'\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "\n",
    "#karena value kolom genres terdapat multiple values, jadi kita akan bungkus menjadi list of list\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fbd9f4",
   "metadata": {},
   "source": [
    "# Reformat table base_df\n",
    "\n",
    "Rename-lah kolom berikut:\n",
    "- primaryTitle -> title\n",
    "- titleType -> type\n",
    "- startYear -> start\n",
    "- runtimeMinutes -> duration\n",
    "- averageRating -> rating\n",
    "- numVotes -> votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a66364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "#Drop kolom tconst, isAdult, endYear, originalTitle\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "print(base_drop2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278ea67",
   "metadata": {},
   "source": [
    "# Klasifikasi Metadata\n",
    "klasifikasikan berdasarkan metadata genres, primaryName (cast name), director name, dan writer_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ffbc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    title           cast_name                       genres  \\\n",
      "0         The Love Expert  [Natalie Talmadge]            [Comedy, Romance]   \n",
      "1               Yes or No  [Natalie Talmadge]                    [Unknown]   \n",
      "2         Our Hospitality  [Natalie Talmadge]  [Comedy, Romance, Thriller]   \n",
      "3       The King of Kings     [Reeka Roberts]  [Biography, Drama, History]   \n",
      "4  I Cover the Waterfront     [James Hackett]             [Drama, Romance]   \n",
      "\n",
      "                       director_name  \\\n",
      "0                   [David Kirkland]   \n",
      "1                [Roy William Neill]   \n",
      "2  [Buster Keaton, John G. Blystone]   \n",
      "3                 [Cecil B. DeMille]   \n",
      "4                      [James Cruze]   \n",
      "\n",
      "                                         writer_name  \n",
      "0                         [John Emerson, Anita Loos]  \n",
      "1   [Arthur F. Goodrich, Burns Mantle, Mary Murillo]  \n",
      "2  [Jean C. Havez, Clyde Bruckman, Joseph A. Mitc...  \n",
      "3                                [Jeanie Macpherson]  \n",
      "4               [Max Miller, Wells Root, Jack Jevne]  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "#Klasifikasi berdasar title, cast_name, genres, director_name, dan writer_name\n",
    "feature_df = base_drop2[['title', 'cast_name', 'genres', 'director_name', 'writer_name']]\n",
    "\n",
    "#Tampilkan 5 baris teratas\n",
    "print(feature_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f492c9a9",
   "metadata": {},
   "source": [
    "# Pertanyaan 1: Bagaimana cara membuat fungsi untuk strip spaces dari setiap row dan setiap elemennya?\n",
    "\n",
    "Lengkapilah function sanitize yang digunakan untuk melakukan strip spaces dari setiap row dan setiap elemennya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90fbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        #kalau cell berisi list\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        #kalau cell berisi string\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "        \n",
    "#Kolom : cast_name, genres, writer_name, director_name        \n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "#Apply function sanitize \n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda19df",
   "metadata": {},
   "source": [
    "# Pertanyaan 2: Bagaimana cara membuat fungsi untuk membuat metadata soup (menggabungkan semua feature menjadi 1 bagian kalimat) untuk setiap judulnya?\n",
    "\n",
    "Lengkapi function soup_feature yang digunakan untuk menggabungkan semua feature  menjadi 1 bagian "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce2bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)\n",
    "\n",
    "#kolom yang digunakan : cast_name, genres, director_name, writer_name\n",
    "def soup_feature(x):\n",
    "    return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "#membuat soup menjadi 1 kolom \n",
    "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183b364",
   "metadata": {},
   "source": [
    "# Pertanyaan 3: Cara menyiapkan CountVectorizer (stop_words = english) dan fit dengan soup\n",
    "\n",
    "CountVectorizer adalah tipe paling sederhana dari vectorizer. Supaya lebih mudah akan dijelaskan melalui contoh di bawah ini:\n",
    "\n",
    "bayangkan terdapat 3 text A, B, dan C, dimana text nya adalah\n",
    "\n",
    "A: The Sun is a star\n",
    "B: My Love is like a red, red rose\n",
    "C : Mary had a little lamb\n",
    "Sekarang kita harus konversi text-text ini menjadi bentuk vector menggunakan CountVectorizer. Langkah-langkahnya adalah: menghitung ukuran dari vocabulary. Vocabulary adalah jumlah dari kata unik yang ada dari text tersebut.\n",
    "\n",
    "\n",
    "Oleh sebab itu, vocabulary dari set ketiga text tersebut adalah: the, sun, is, a, star, my, love, like, red, rose, mary, had, little, lamb. Secara total, ukuran vocabulary adalah 14.\n",
    "\n",
    "\n",
    "Tetapi, biasanya kita tidak include stop words (english), seperti as, is, a, the, dan sebagainya karena itu adalah kata yang sudah common sekali.\n",
    "\n",
    "\n",
    "Dengan mengeliminasi stop words, maka clean size vocabulary kita adalah like, little, lamb, love, mary, red, rose, sun, star (sorted alphabet ascending)\n",
    "Maka, dengan menggunakan CountVectorizer, maka hasil yang kita dapatkan adalah sebagai berikut:\n",
    "\n",
    "\n",
    "A : (0,0,0,0,0,0,0,1,1), terdiri atas sun:1, star:1\n",
    "B : (1,0,0,1,0,2,1,0,0), terdiri atas like:1, love:1, red:2, rose:1\n",
    "C : (0,1,1,0,1,0,0,0,0), terdiri atas little:1, lamb:1, mary:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300d9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)\n",
    "\n",
    "def soup_feature(x):\n",
    "    return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n",
    "\n",
    "#import CountVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#definisikan CountVectorizer dan mengubah soup tadi menjadi bentuk vector\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(feature_df['soup'])\n",
    "\n",
    "print(count)\n",
    "print(count_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ca47b",
   "metadata": {},
   "source": [
    "# Pertanyaan 4: Cara membuat model similarity antara count matrix\n",
    "\n",
    "menghitung score cosine similarity dari setiap pasangan judul (berdasarkan semua kombinasi pasangan yang ada, dengan kata lain kita akan membuat 675 x 675 matrix, dimana cell di kolom i dan j menunjukkan score similarity antara judul i dan j. kita dapat dengan mudah melihat bahwa matrix ini simetris dan setiap elemen pada diagonal adalah 1, karena itu adalah similarity score dengan dirinya sendiri.\n",
    "\n",
    "menghitung score cosine similarity dari setiap pasangan judul (berdasarkan semua kombinasi pasangan yang ada, dengan kata lain kita akan membuat 675 x 675 matrix, dimana cell di kolom i dan j menunjukkan score similarity antara judul i dan j. kita dapat dengan mudah melihat bahwa matrix ini simetris dan setiap elemen pada diagonal adalah 1, karena itu adalah similarity score dengan dirinya sendiri.\n",
    "\n",
    "output yang didapat antara range -1 sampai 1. Score yang hampir mencapai 1 artinya kedua entitas tersebut sangatlah mirip sedangkan score yang hampir mencapai -1 artinya kedua entitas tersebut adalah beda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de3607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)\n",
    "\n",
    "def soup_feature(x):\n",
    "    return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(feature_df['soup'])\n",
    "\n",
    "#Import cosine_similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Gunakan cosine_similarity antara count_matrix \n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "#print hasilnya\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238b741f",
   "metadata": {},
   "source": [
    "# Pertanyaan 5: Cara membuat content based recommender system\n",
    "\n",
    "reverse mapping dengan judul sebagai index nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "215298ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     knownForTitles                   cast_name      tconst titleType  \\\n",
      "848       tt3040964  [Cristina Carrión Márquez]   tt3040964     movie   \n",
      "383       tt0286336          [Francisco Bretas]   tt0286336  tvSeries   \n",
      "1002      tt7222086          [Hiroki Matsukawa]   tt7222086  tvSeries   \n",
      "73        tt0075147             [Joaquín Parra]   tt0075147     movie   \n",
      "232       tt0119051            [Chris Kosloski]   tt0119051     movie   \n",
      "556      tt10068158          [Hiroki Matsukawa]  tt10068158     movie   \n",
      "9         tt0028657            [Bernard Loftus]   tt0028657     movie   \n",
      "191       tt0107875               [Simon Mayal]   tt0107875     movie   \n",
      "803       tt2356464               [Sina Müller]   tt2356464     movie   \n",
      "983       tt6270328                   [Jo Boag]   tt6270328  tvSeries   \n",
      "\n",
      "                                         primaryTitle  \\\n",
      "848                                   The Jungle Book   \n",
      "383                      The Animals of Farthing Wood   \n",
      "1002                                    Made in Abyss   \n",
      "73                                   Robin and Marian   \n",
      "232                                          The Edge   \n",
      "556                     Made in Abyss: Journey's Dawn   \n",
      "9                               Boss of Lonely Valley   \n",
      "191                       The Princess and the Goblin   \n",
      "803                                           Ostwind   \n",
      "983   The Skinner Boys: Guardians of the Lost Secrets   \n",
      "\n",
      "                                        originalTitle  isAdult  startYear  \\\n",
      "848                                   The Jungle Book        0     2016.0   \n",
      "383                      The Animals of Farthing Wood        0     1993.0   \n",
      "1002                                    Made in Abyss        0     2017.0   \n",
      "73                                   Robin and Marian        0     1976.0   \n",
      "232                                          The Edge        0     1997.0   \n",
      "556                 Made in Abyss: Tabidachi no Yoake        0     2019.0   \n",
      "9                               Boss of Lonely Valley        0     1937.0   \n",
      "191                       The Princess and the Goblin        0     1991.0   \n",
      "803                                           Ostwind        0     2013.0   \n",
      "983   The Skinner Boys: Guardians of the Lost Secrets        0     2014.0   \n",
      "\n",
      "      endYear  runtimeMinutes                       genres  averageRating  \\\n",
      "848       NaN           106.0       Adventure,Drama,Family            7.4   \n",
      "383    1995.0            25.0    Adventure,Animation,Drama            8.3   \n",
      "1002      NaN           325.0    Adventure,Animation,Drama            8.4   \n",
      "73        NaN           106.0      Adventure,Drama,Romance            6.5   \n",
      "232       NaN           117.0       Action,Adventure,Drama            6.9   \n",
      "556       NaN           139.0  Adventure,Animation,Fantasy            7.4   \n",
      "9         NaN            60.0       Action,Adventure,Drama            6.2   \n",
      "191       NaN            82.0   Adventure,Animation,Comedy            6.8   \n",
      "803       NaN           101.0       Adventure,Drama,Family            6.8   \n",
      "983       NaN            23.0    Adventure,Animation,Drama            7.8   \n",
      "\n",
      "      numVotes                                      director_name  \\\n",
      "848     250994                                      [Jon Favreau]   \n",
      "383       3057             [Elphin Lloyd-Jones, Philippe Leclerc]   \n",
      "1002      4577  [Masayuki Kojima, Hitoshi Haga, Shinya Iino, T...   \n",
      "73       10830                                   [Richard Lester]   \n",
      "232      65673                                     [Lee Tamahori]   \n",
      "556         81                                  [Masayuki Kojima]   \n",
      "9           41                                       [Ray Taylor]   \n",
      "191       2350                                     [József Gémes]   \n",
      "803       1350                                [Katja von Garnier]   \n",
      "983         12        [Pablo De La Torre, Eugene Linkov, Jo Boag]   \n",
      "\n",
      "                                            writer_name  \n",
      "848                     [Justin Marks, Rudyard Kipling]  \n",
      "383   [Valerie Georgeson, Colin Dann, Jenny McDade, ...  \n",
      "1002  [Akihito Tsukushi, Keigo Koyanagi, Hideyuki Ku...  \n",
      "73                                      [James Goldman]  \n",
      "232                                       [David Mamet]  \n",
      "556                                  [Akihito Tsukushi]  \n",
      "9                       [Frances Guihan, Forrest Brown]  \n",
      "191                     [Robin Lyons, George MacDonald]  \n",
      "803          [Kristina Magdalena Henn, Lea Schmidbauer]  \n",
      "983   [David Witt, John Derevlany, David Evans, Pete...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_15180/2408548965.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df[col] = feature_df[col].apply(sanitize)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp/ipykernel_15180/2408548965.py:66: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "movie_rating_df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/movie_rating_df.csv')\n",
    "\n",
    "director_writers = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/directors_writers.csv')\n",
    "director_writers['director_name'] = director_writers['director_name'].apply(lambda row: row.split(','))\n",
    "director_writers['writer_name'] = director_writers['writer_name'].apply(lambda row: row.split(','))\n",
    "\n",
    "name_df = pd.read_csv('https://dqlab-dataset.s3-ap-southeast-1.amazonaws.com/actor_name.csv')\n",
    "name_df = name_df[['nconst','primaryName','knownForTitles']]\n",
    "name_df['knownForTitles'] = name_df['knownForTitles'].apply(lambda x: x.split(','))\n",
    "\n",
    "df_uni = []\n",
    "for x in ['knownForTitles']:\n",
    "    idx = name_df.index.repeat(name_df['knownForTitles'].str.len())\n",
    "    df1 = pd.DataFrame({\n",
    "        x: np.concatenate(name_df[x].values)\n",
    "    })\n",
    "    df1.index = idx\n",
    "    df_uni.append(df1)\n",
    "\n",
    "df_concat = pd.concat(df_uni, axis=1)\n",
    "unnested_df = df_concat.join(name_df.drop(['knownForTitles'], 1), how='left')\n",
    "unnested_df = unnested_df[name_df.columns.tolist()]\n",
    "\n",
    "unnested_drop = unnested_df.drop(['nconst'], axis=1)\n",
    "df_uni = []\n",
    "for col in ['primaryName']:\n",
    "    dfi = unnested_drop.groupby(['knownForTitles'])[col].apply(list)\n",
    "    df_uni.append(dfi)\n",
    "df_grouped = pd.concat(df_uni, axis=1).reset_index()\n",
    "df_grouped.columns = ['knownForTitles','cast_name']\n",
    "\n",
    "base_df = pd.merge(df_grouped, movie_rating_df, left_on='knownForTitles', right_on='tconst', how='inner')\n",
    "base_df = pd.merge(base_df, director_writers, left_on='tconst', right_on='tconst', how='left')\n",
    "\n",
    "base_drop = base_df.drop(['knownForTitles'], axis=1)\n",
    "base_drop['genres'] = base_drop['genres'].fillna('Unknown')\n",
    "base_drop[['director_name','writer_name']] = base_drop[['director_name','writer_name']].fillna('unknown')\n",
    "base_drop['genres'] = base_drop['genres'].apply(lambda x: x.split(','))\n",
    "\n",
    "base_drop2 = base_drop.drop(['tconst','isAdult','endYear','originalTitle'], axis=1)\n",
    "base_drop2 = base_drop2[['primaryTitle','titleType','startYear','runtimeMinutes','genres','averageRating','numVotes','cast_name','director_name','writer_name']]\n",
    "base_drop2.columns = ['title','type','start','duration','genres','rating','votes','cast_name','director_name','writer_name']\n",
    "\n",
    "feature_df = base_drop2[['title','cast_name','genres','director_name','writer_name']]\n",
    "\n",
    "def sanitize(x):\n",
    "    try:\n",
    "        if isinstance(x, list):\n",
    "            return [i.replace(' ','').lower() for i in x]\n",
    "        else:\n",
    "            return [x.replace(' ','').lower()]\n",
    "    except:\n",
    "        print(x)\n",
    "feature_cols = ['cast_name','genres','writer_name','director_name']\n",
    "\n",
    "for col in feature_cols:\n",
    "    feature_df[col] = feature_df[col].apply(sanitize)\n",
    "\n",
    "def soup_feature(x):\n",
    "    return ' '.join(x['cast_name']) + ' ' + ' '.join(x['genres']) + ' ' + ' '.join(x['director_name']) + ' ' + ' '.join(x['writer_name'])\n",
    "\n",
    "feature_df['soup'] = feature_df.apply(soup_feature, axis=1)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english')\n",
    "count_matrix = count.fit_transform(feature_df['soup'])\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "indices = pd.Series(feature_df.index, index=feature_df['title']).drop_duplicates()\n",
    "\n",
    "def content_recommender(title):\n",
    "    #mendapatkan index dari judul film (title) yang disebutkan\n",
    "    idx = indices[title]\n",
    "\n",
    "    #menjadikan list dari array similarity cosine sim \n",
    "    #hint: cosine_sim[idx]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    #mengurutkan film dari similarity tertinggi ke terendah\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #untuk mendapatkan list judul dari item kedua sampe ke 11\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    #mendapatkan index dari judul-judul yang muncul di sim_scores\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    #dengan menggunakan iloc, kita bisa panggil balik berdasarkan index dari movie_indices\n",
    "    return base_df.iloc[movie_indices]\n",
    "\n",
    "#aplikasikan function di atas\n",
    "print(content_recommender('The Lion King'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
